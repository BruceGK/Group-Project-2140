{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c41e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mig/Desktop/pitt/projects/Group-Project-2140/cord_ir\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cf7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from search.elastic_index_reader import IndexReader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from search.data_loader import DataLoader\n",
    "import pandas as pd\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa436d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "queryTree = ET.parse('../data/2020-07-16/eval/topics-rnd5.xml')\n",
    "queryRoot = queryTree.getroot()\n",
    "queries = []\n",
    "for child in queryRoot:\n",
    "    query = {\n",
    "        'queryNo': child.attrib['number'],\n",
    "        'query': child.find('query').text,\n",
    "        'question': child.find('question').text,\n",
    "        'narrative': child.find('narrative').text\n",
    "    }\n",
    "    queries.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac5006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"../data/models\").mkdir(parents=True, exist_ok=True)\n",
    "loader = DataLoader('../data/2020-07-16')\n",
    "loader.load_metadata_mappings(loader.load_metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794c2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = IndexReader()\n",
    "# iterator for the training documents\n",
    "class DocIter:\n",
    "    def __init__(self, pbar=True):\n",
    "        metadata = loader.load_metadata()\n",
    "        # only use rows that have file info\n",
    "        self.metadata = metadata[pd.notna(metadata['pmc_json_files']) | pd.notna(metadata['pdf_json_files'])]\n",
    "        self.rows = self.metadata.shape[0]\n",
    "        self.current = 0\n",
    "        if pbar:\n",
    "            self.pbar = tqdm(total=self.rows)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.rows\n",
    "\n",
    "    def __next__(self): \n",
    "        if self.current < self.rows:\n",
    "            row = self.metadata.iloc[self.current]\n",
    "            self.current += 1\n",
    "            docData = loader.load_paper_data(row)\n",
    "            text = docData['data']['main_text']\n",
    "#             tokens = [t['token'] for t in reader.tokenize(text)['tokens']]\n",
    "#             text = ' '.join(tokens)\n",
    "            if hasattr(self, 'pbar'):\n",
    "                self.pbar.update(1)\n",
    "            return text\n",
    "        if hasattr(self, 'pbar'):\n",
    "            self.pbar.close()\n",
    "        raise StopIteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d97f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6697821",
   "metadata": {},
   "outputs": [],
   "source": [
    "docIterator = DocIter()\n",
    "vectorizer.fit(docIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ad671",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(vectorizer, '../data/models/tfidf.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859c7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = load('../data/models/tfidf.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d96dfe75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643295"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a020a648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c834dc15facc446a9ae8e10b5943f611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/info-retri/lib/python3.9/site-packages/elasticsearch/connection/base.py:209: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "judgments = {q['queryNo']: [] for q in queries}\n",
    "with open('../data/2020-07-16/eval/qrels-covid_d5_j0.5-5.txt', 'r') as qrels:\n",
    "    for line in qrels:\n",
    "        [topicId, iteration, cordId, judgment] = line.strip('\\n').split(' ')\n",
    "        judgments[topicId].append({\n",
    "            'iteration': iteration,\n",
    "            'cordId': cordId,\n",
    "            'judgment': judgment\n",
    "        })\n",
    "# candidate set, select  non-relevant docs in results to add in training data\n",
    "def getRetrievalResults(queries, field):\n",
    "    results = {}\n",
    "    for query in tqdm(queries):\n",
    "        res = reader.search(\"cord_test\", query[field], size=500, fields=[], highlight=False)\n",
    "        results[query['queryNo']] = res['hits']['hits']\n",
    "    return results\n",
    "candidates = getRetrievalResults(queries, 'question')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88108b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ac89a8f6944c9d9545783ba614ad02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the training data\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "# feature X for each row is [[tfidf of query], [tfidf of document]]\n",
    "X = coo_matrix((0, len(vocabulary) * 2))\n",
    "y = []\n",
    "group_counts = []\n",
    "for query in tqdm(queries):\n",
    "    queryNo = query['queryNo']\n",
    "    queryTfIdf = vectorizer.transform([query['query']])\n",
    "    questionTfIdf = vectorizer.transform([query['question']])\n",
    "    retrieved = candidates[queryNo]\n",
    "    queryResults = list(judgments[queryNo])\n",
    "    for doc in retrieved:\n",
    "        docId = doc['_id']\n",
    "        if len([e for e in queryResults if e['cordId'] == docId]) == 0:\n",
    "            queryResults.append({\n",
    "                'cordId': docId,\n",
    "                'judgment': 0\n",
    "            })\n",
    "    text_list = []\n",
    "    for item in queryResults:\n",
    "        paper_data = loader.load_paper_data(item['cordId'])\n",
    "        main_text = paper_data['data']['main_text']\n",
    "        text_list.append(main_text)\n",
    "    # batch transform\n",
    "    y.extend(map(lambda e: e['judgment'], queryResults))\n",
    "    y.extend(map(lambda e: e['judgment'], queryResults))\n",
    "    textTfIdf = vectorizer.transform(text_list)\n",
    "    queryTfIdf = vstack([queryTfIdf for i in range(len(queryResults))])\n",
    "    questionTfIdf = vstack([questionTfIdf for i in range(len(queryResults))])\n",
    "    queryRows = hstack([queryTfIdf, textTfIdf])\n",
    "    questionRows = hstack([questionTfIdf, textTfIdf])\n",
    "    X = vstack([X, queryRows, questionRows])\n",
    "    group_counts.append(len(queryResults))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccda19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "ranker = lgb.LGBMRanker(task=\"train\",\n",
    "        objective=\"lambdarank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcf544",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = ranker.fit(X, y, group=group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132a5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81972634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
